[{"path":"index.html","id":"session-info","chapter":"Session info","heading":"Session info","text":"","code":"R version 4.0.3 (2020-10-10)\nRStudio version 1.4.1106\nWindows 10 x64##  package        * version date       lib source        \n##  bookdown         0.24    2021-09-02 [1] CRAN (R 4.0.5)\n##  broom            0.7.6   2021-04-05 [1] CRAN (R 4.0.5)\n##  bslib            0.2.5.1 2021-05-18 [1] CRAN (R 4.0.3)\n##  downlit          0.2.1   2020-11-04 [1] CRAN (R 4.0.5)\n##  dplyr            1.0.5   2021-03-05 [1] CRAN (R 4.0.4)\n##  ellipse          0.4.2   2020-05-27 [1] CRAN (R 4.0.5)\n##  ggplot2          3.3.3   2020-12-30 [1] CRAN (R 4.0.4)\n##  knitr            1.31    2021-01-27 [1] CRAN (R 4.0.4)\n##  palmerpenguins   0.1.0   2020-07-23 [1] CRAN (R 4.0.5)\n##  rmarkdown        2.9     2021-06-15 [1] CRAN (R 4.0.5)\n##  svglite          2.0.0   2021-02-20 [1] CRAN (R 4.0.5)\n##  tibble           3.1.0   2021-02-25 [1] CRAN (R 4.0.4)\n##  tidyr            1.1.3   2021-03-03 [1] CRAN (R 4.0.4)\n## \n## [1] C:/Users/Adam/Documents/R/win-library/4.0\n## [2] C:/Program Files/R/R-4.0.3/library"},{"path":"lab-1-september-15.html","id":"lab-1-september-15","chapter":"1 Lab 1 — September 15","heading":"1 Lab 1 — September 15","text":"","code":""},{"path":"lab-1-september-15.html","id":"review-of-r-basics","chapter":"1 Lab 1 — September 15","heading":"1.1 Review of R basics","text":"R name programming language. RStudio name integrated development\nenvironment (IDE). application running RStudio.already , R can downloaded .\nRStudio (desktop version) can downloaded\n. R installed \ninstalling RStudio.already R installed device, ensure version >= 4.0.0. Otherwise,\nuse links install latest version.","code":""},{"path":"lab-1-september-15.html","id":"configure-rstudio-settings","chapter":"1 Lab 1 — September 15","heading":"1.1.1 Configure RStudio settings","text":"settings can found Tools -> Global Options....Uncheck boxes modify dropdowns mention saving items upon exit restoring items\nupon startup. ensure RStudio starts fresh session time.","code":""},{"path":"lab-1-september-15.html","id":"console-pane","chapter":"1 Lab 1 — September 15","heading":"1.1.2 Console pane","text":"RStudio application opened, Console pane occupy entirety left\nside. (Open image new tab small)code typed Console evaluated immediately upon pressing Enter.\nneed evaluate multi-line code, Shift + Enter used \ncreate line breaks.Console often used evaluate code may part main analyses. \nincludes checking work, testing code, modifying settings, etc.","code":""},{"path":"lab-1-september-15.html","id":"source-pane","chapter":"1 Lab 1 — September 15","heading":"1.1.3 Source pane","text":"RStudio application opened, Source pane hidden default. Source\npane modify R scripts type main code analyses. strongly\nrecommended save important code (code may need revisit later\ndate) inside R script file. new R script can created using:File -> New File -> R Script, orCtrl + Shift + N, orClicking  selecting \"R Script\"Source pane appear top left open R script.\n(Open image new tab small)Code typed script file evaluated upon pressing Enter. Code must \nsent Source Console evaluation.run single line code, place typing cursor anywhere line press\nCtrl + Enter.run multiple lines code, highlight desired lines press Ctrl +\nEnter.run entire script start finish, click  .","code":""},{"path":"lab-1-september-15.html","id":"environment-pane","chapter":"1 Lab 1 — September 15","heading":"1.1.4 Environment pane","text":"Environment pane top right pane RStudio. pane shows variables \ninitialised current R session. variables current R session can removed\nclicking broom icon. Alternatively, switching Grid view List view allow \nremove selected variables.","code":""},{"path":"lab-1-september-15.html","id":"comments","chapter":"1 Lab 1 — September 15","heading":"1.1.5 Comments","text":"Comments can added R script prepending # symbol.","code":""},{"path":"lab-1-september-15.html","id":"variables","chapter":"1 Lab 1 — September 15","heading":"1.1.6 Variables","text":"Variables created using convention name <- value.variable successfully initialised, appear Environment pane. \nsimple variables, value variable can seen Environment pane. variables\nwhose values visible Environment pane, values can checked calling\nConsole:using RStudio's built-viewer typing Console:naming variables, try use names already exist R data sets functions. \ncan checked partially typing variable name seeing suggestions come . \nexample, reading data, name variable data since already exists\ndata() function R.","code":"\nvar1 <- 3\nvar1## [1] 3\nView(var1)"},{"path":"lab-1-september-15.html","id":"vectors","chapter":"1 Lab 1 — September 15","heading":"1.1.7 Vectors","text":"Vectors univariate data structures. Vectors can created using c() function \nelements separated commas.Note examplevar1 actually vector length 1.calling vectors Console, note numbers square brackets \ncorresponding output represent position number first element line.","code":"\nnums <- c(9, 12, 20)\nwords <- c(\"apple\", \"orange\", \"banana\")\nvar1 <- 3\nvar2 <- 1:30\n\nvar2##  [1]  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25\n## [26] 26 27 28 29 30"},{"path":"lab-1-september-15.html","id":"extracting-elements","chapter":"1 Lab 1 — September 15","heading":"1.1.7.1 Extracting elements","text":"elements vectors can extracted supplying vector positive integers inside square\nbrackets. Note R, indices begin 1.","code":"\nvar2[7]## [1] 7\nvar2[c(2, 7, 9, 11, 20)]## [1]  2  7  9 11 20"},{"path":"lab-1-september-15.html","id":"deleting-elements","chapter":"1 Lab 1 — September 15","heading":"1.1.7.2 Deleting elements","text":"elements vectors can deleted supplying vector negative integers placing \nnegative outside vector positive integers, inside square brackets.\nNote R, indices begin 1.","code":"\nvar2[-7]##  [1]  1  2  3  4  5  6  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26\n## [26] 27 28 29 30\nvar2[c(-2, -7, -9, -11, -20)]##  [1]  1  3  4  5  6  8 10 12 13 14 15 16 17 18 19 21 22 23 24 25 26 27 28 29 30\nvar2[-c(2, 7, 9, 11, 20)]##  [1]  1  3  4  5  6  8 10 12 13 14 15 16 17 18 19 21 22 23 24 25 26 27 28 29 30"},{"path":"lab-1-september-15.html","id":"data-frames","chapter":"1 Lab 1 — September 15","heading":"1.1.8 Data frames","text":"Data frames multivariate data structures. Data frames can thought vertical\nconcatentation vectors. cases, column data frame contains values \nsingle variable row data frame contains values variable single\nobservation. example, consider following data set:example , column contains values single variable row contains\nvalues variable single observation (patient).Things note:Data frames can created supplying name-value pairs data.frame() function.Name-value pairs supplied using = rather <-.name-value pair must length. Missing values can represented using NA.","code":"\npatients <- data.frame(\n  patient_id = c(\"123abc\", \"28fnr8\", \"02jr8d\", \"r82j45\", \"t90ro5\"),\n  height = c(181, 145, 190, 210, 94),\n  mass = c(85, 72, 82, 90, 60),\n  sex = c(\"M\", \"F\", \"M\", \"F\", \"F\")\n)\n\npatients##   patient_id height mass sex\n## 1     123abc    181   85   M\n## 2     28fnr8    145   72   F\n## 3     02jr8d    190   82   M\n## 4     r82j45    210   90   F\n## 5     t90ro5     94   60   F"},{"path":"lab-1-september-15.html","id":"extracting-columns","chapter":"1 Lab 1 — September 15","heading":"1.1.8.1 Extracting columns","text":"Columns data frame can extracted vectors using dollar sign ($).","code":"\npatients$height## [1] 181 145 190 210  94\npatients$sex## [1] \"M\" \"F\" \"M\" \"F\" \"F\""},{"path":"lab-1-september-15.html","id":"extracting-rows-and-subsets","chapter":"1 Lab 1 — September 15","heading":"1.1.8.2 Extracting rows and subsets","text":"Thinking data frames matrices, can subsetted supplying row column\npositions/names separated comma within square brackets:","code":"\n# Extract row 3 and all columns\npatients[3, ]##   patient_id height mass sex\n## 3     02jr8d    190   82   M\n# Extract rows 1, 4, and 5, and columns 1 and 3\npatients[c(1, 4, 5), c(1, 3)]##   patient_id mass\n## 1     123abc   85\n## 4     r82j45   90\n## 5     t90ro5   60\n# Extract rows 1, 4, and 5, and columns \"patient_id\" and \"mass\"\npatients[c(1, 4, 5), c(\"patient_id\", \"mass\")]##   patient_id mass\n## 1     123abc   85\n## 4     r82j45   90\n## 5     t90ro5   60\n# Extract everything *except* rows 2 and 3, and columns 2 and 3\npatients[-c(2, 3), -c(2, 3)]##   patient_id sex\n## 1     123abc   M\n## 4     r82j45   F\n## 5     t90ro5   F"},{"path":"lab-1-september-15.html","id":"the-working-directory","chapter":"1 Lab 1 — September 15","heading":"1.1.9 The working directory","text":"working directory folder path working . path current\nworking directory can found immediately underneath Console tab heading.opening first instance RStudio using application directly, working directory \nautomatically set \n\"Default working directory (project)\". first\ninstance RStudio opened opening R script file (files ending .R), working directory\nautomatically set folder R script file located.Note opening first instance RStudio, scripts opened \nchange working directory.working directory important keep track reading writing files. sake \norganization, may case following folder structure:dot represents currently (working directory).example , R scripts contained working directory, data output\nfiles folders working directory. , reading files need specify\nread \"data\" folder. Similarly, writing files, need specify\nwritten \"output\" folder.able , need talk file folder paths specify .","code":".\n├── data\n│   └── my_data.txt\n├── output\n│   ├── output1.txt\n│   └── model.RDS\n├── script1.R\n└── script2.R"},{"path":"lab-1-september-15.html","id":"paths","chapter":"1 Lab 1 — September 15","heading":"1.1.10 Paths","text":"path string (.e. needs surrounded quotes) describes location file \nfolder device. Paths become extremely important reading writing files R. Paths\ncan broken two categories: absolute relative.","code":""},{"path":"lab-1-september-15.html","id":"absolute-paths","chapter":"1 Lab 1 — September 15","heading":"1.1.10.1 Absolute paths","text":"absolute path gives full location file/folder device, irrespective \ncurrent working directory, e.g.use absolute paths creates problems.Suppose Windows include path like \"C:/Users/Adam/Desktop/blah.R\" \nscript. execute code given Windows machine, likely\nwork since name probably Adam blah.R may located Desktop\nlike mine.Suppose Windows include path like \"C:/Users/Adam/Desktop/blah.R\" \nscript. execute code given Windows machine, likely\nwork since name probably Adam blah.R may located Desktop\nlike mine.users Windows, addition folders possibly existing, likely\n\"C drive\".users Windows, addition folders possibly existing, likely\n\"C drive\"., use absolute paths recommended complicates sharing code\ndevices platform-dependent.","code":"\"C:/Users/Adam/Desktop/blah.R\"\n\"/Users/John/Documents/lab1.txt\""},{"path":"lab-1-september-15.html","id":"relative-paths","chapter":"1 Lab 1 — September 15","heading":"1.1.10.2 Relative paths","text":"relative path gives partial location file/folder relative working directory.\nAlthough use relative paths still assumes identical partial folder structure, \nassume identical folder structure root path.two helpers specifying relative paths: dot, \".\", double-dot, \"..\". \ndot, \".\", can thought shorthand \"\", current working directory. \ndouble-dot, \"..\", means \"go one level\".Example 1:Suppose working directory \"C:/Users/Adam/Desktop\" structure:Inside script1.R, want read data found my_data.txt. can done using:rather using:Example 2:Suppose working directory \"C:/Users/Adam/Desktop/model\" surrounding folder\nstructure:Inside model.R, want read data found my_data.txt. can done using:rather using:","code":"C:/Users/Adam/Desktop **you are here**\n│\n├── my_data.txt\n└── script1.R\nmy_data <- read.table(\"my_data.txt\") \n## OR ##\nmy_data <- read.table(\"./my_data.txt\")\nmy_data <- read.table(\"C:/Users/Adam/Desktop/my_data.txt\")C:/Users/Adam/Desktop\n│\n├── data\n│   └── my_data.txt\n├── model **you are here**\n│   ├── output1.txt\n│   └── model.R\n├── output\n│   ├── output1.txt\n│   └── output2.RDS\n└── other.R\nmy_data <- read.table(\"../data/my_data.txt\")\nmy_data <- read.table(\"C:/Users/Adam/Desktop/data/my_data.txt\")"},{"path":"lab-1-september-15.html","id":"reading-in-data","chapter":"1 Lab 1 — September 15","heading":"1.1.11 Reading in data","text":"course, () data read .txt file header. \ncode use :instances, may need:","code":"\nmy_data <- read.table(\"path/to/data/file.txt\", header=TRUE)\nmy_data <- read.table(\"path/to/data/file.txt\", header=TRUE, stringsAsFactors=TRUE)"},{"path":"lab-1-september-15.html","id":"accessing-the-built-in-documentation","chapter":"1 Lab 1 — September 15","heading":"1.1.12 Accessing the built-in documentation","text":"Prepending function built-data set question mark bring associated\ndocumentation. example, Console, try:","code":"\n?read.table\n?lm\n?rock"},{"path":"lab-1-september-15.html","id":"introduction-to-simple-linear-regression","chapter":"1 Lab 1 — September 15","heading":"1.2 Introduction to simple linear regression","text":"Note: content contained following sections aid answering Assignment 1\nQuestion 5.","code":""},{"path":"lab-1-september-15.html","id":"loading-the-data","chapter":"1 Lab 1 — September 15","heading":"1.2.1 Loading the data","text":"data set using can found file named table1.1_DS.txt. Since \ntext file header, use read.table() read specify header=TRUE.data contained folder called \"data\" current working directory. path use\nread data depend saved data.can get dimensions data set using functions dim(), nrow(), ncol().can get column names data set using names() function.can preview data read using head() function. head function useful\nespecially larger data sets printing entire data set may desirable. \ndefault, function return first six rows data.can also use RStudio's built-object viewer view full data set. Environment\npane:List view, click row corresponding variable containing data.Grid view, click row corresponding variable containing data \n\"Value\" heading.Alternatively, can use View() function:","code":"\ntable1.1 <- read.table(\"./data/table1.1_DS.txt\", header=TRUE)\ndim(table1.1)## [1] 25  2\nnrow(table1.1)## [1] 25\nncol(table1.1)## [1] 2\nnames(table1.1)## [1] \"y\" \"x\"\nhead(table1.1)##       y    x\n## 1 10.98 35.3\n## 2 11.13 29.7\n## 3 12.51 30.8\n## 4  8.40 58.8\n## 5  9.27 61.4\n## 6  8.73 71.3\nView(table1.1)"},{"path":"lab-1-september-15.html","id":"creating-the-data-manually","chapter":"1 Lab 1 — September 15","heading":"1.2.2 Creating the data manually","text":"Assignment 1 Question 5, given data ordered pairs need manually\nenter R. Using first ten observations table1.1 example, can create \ndata frame manually:(continue using full Table 1.1 demonstrations ).","code":"\ntable1.1_manual <- data.frame(\n  y = c(10.98, 11.13, 12.51, 8.40, 9.27, 8.73, 6.36, 8.50, 7.82, 9.14),\n  x = c(35.3, 29.7, 30.8, 58.8, 61.4, 71.3, 74.4, 76.7, 70.7, 57.5)\n)\n\nhead(table1.1_manual)##       y    x\n## 1 10.98 35.3\n## 2 11.13 29.7\n## 3 12.51 30.8\n## 4  8.40 58.8\n## 5  9.27 61.4\n## 6  8.73 71.3"},{"path":"lab-1-september-15.html","id":"fitting-the-slr-model","chapter":"1 Lab 1 — September 15","heading":"1.2.3 Fitting the SLR model","text":"Linear regression models fit using lm() function. first need fit model\\[Y_{} \\,=\\, \\beta_{0} \\,+\\, \\beta_{1}X_{} \\,+\\, \\varepsilon_{}, \\quad =1,\\ldots,n\\]order determine whether\\[Y_{} \\,=\\, \\beta_{0} \\,+\\, \\varepsilon_{}, \\quad =1,\\ldots,n\\]appropriate model.code says build linear regression model using y dependent (response)\nvariable, x independent (predictor) variable, variables y x \nfound within table1.1 data variable. Although need specify intercept \nformula specification, linear regression models built lm() include intercept default.","code":"\nslr_model <- lm(y ~ x, data=table1.1)"},{"path":"lab-1-september-15.html","id":"inspecting-the-model","chapter":"1 Lab 1 — September 15","heading":"1.2.4 Inspecting the model","text":"can obtain summary linear regression model using summary() function.information , fitted regression line equation:\\[\\widehat{y}_{} \\,=\\, 13.62 \\,-\\, 0.08x_{} \\quad =1,\\ldots,n\\]","code":"\nsummary(slr_model)## \n## Call:\n## lm(formula = y ~ x, data = table1.1)\n## \n## Residuals:\n##     Min      1Q  Median      3Q     Max \n## -1.6789 -0.5291 -0.1221  0.7988  1.3457 \n## \n## Coefficients:\n##             Estimate Std. Error t value Pr(>|t|)    \n## (Intercept) 13.62299    0.58146  23.429  < 2e-16 ***\n## x           -0.07983    0.01052  -7.586 1.05e-07 ***\n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Residual standard error: 0.8901 on 23 degrees of freedom\n## Multiple R-squared:  0.7144, Adjusted R-squared:  0.702 \n## F-statistic: 57.54 on 1 and 23 DF,  p-value: 1.055e-07"},{"path":"lab-1-september-15.html","id":"is-an-intercept-only-model-appropriate","chapter":"1 Lab 1 — September 15","heading":"1.2.5 Is an intercept-only model appropriate?","text":"determine whether intercept-model appropriate, need test hypotheses:\\[H_{0}: \\beta_{1} \\,=\\, 0, \\quad H_{}: \\beta_{1} \\,\\neq\\, 0\\]value test statistic can read summary table value -7.586 \ncorresponding \\(p\\)-value 1.05e-07. Using significance level \\(\\alpha = 0.05\\), since\n\\(p\\)-value less \\(\\alpha\\), reject null hypothesis conclude \nevidence support claim \\(\\beta_{1}\\) different zero., consider intercept-model.\\(p\\)-value greater \\(\\alpha = 0.05\\) failed reject null\nhypothesis? fit intercept-model?Aside: note (Intercept) row, t-value \\(p\\)-value correspond testing \nhypotheses:\\[H_{0}: \\beta_{0} \\,=\\, 0, \\quad H_{}: \\beta_{0} \\,\\neq\\, 0\\]","code":""},{"path":"lab-1-september-15.html","id":"the-rock-data-set","chapter":"1 Lab 1 — September 15","heading":"1.2.6 The rock data set","text":"fit intercept-model, let us consider rock data set built R. data\nset can loaded using:can preview data usual:","code":"\ndata(rock)\nhead(rock)##   area    peri     shape perm\n## 1 4990 2791.90 0.0903296  6.3\n## 2 7002 3892.60 0.1486220  6.3\n## 3 7558 3930.66 0.1833120  6.3\n## 4 7352 3869.32 0.1170630  6.3\n## 5 7943 3948.54 0.1224170 17.1\n## 6 7979 4010.15 0.1670450 17.1"},{"path":"lab-1-september-15.html","id":"fitting-a-slr","chapter":"1 Lab 1 — September 15","heading":"1.2.7 Fitting a SLR","text":"create simple linear regression model using area dependent (response) variable \nshape independent (predictor) variable.equation fitted line :\\[\\widehat{y}_{} \\,=\\, 8465 \\,-\\, 5855x_{}, \\quad =1,\\ldots,n\\]Testing hypotheses:\\[H_{0}: \\beta_{1} \\,=\\, 0, \\quad H_{}: \\beta_{1} \\,\\neq\\, 0\\]corresponding \\(p\\)-value 0.215. Using significance level \\(\\alpha = 0.05\\), since \n\\(p\\)-value greater 0.05, fail reject null hypothesis. , insufficient\nevidence support claim \\(\\beta_{1}\\) non-zero.Now fit intercept-model!","code":"\nrock_slr_model <- lm(area ~ shape, data=rock)\n\nsummary(rock_slr_model)## \n## Call:\n## lm(formula = area ~ shape, data = rock)\n## \n## Residuals:\n##     Min      1Q  Median      3Q     Max \n## -6101.6 -1512.3   104.6  1765.3  5152.9 \n## \n## Coefficients:\n##             Estimate Std. Error t value Pr(>|t|)    \n## (Intercept)     8465       1087   7.788 6.08e-10 ***\n## shape          -5855       4660  -1.256    0.215    \n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Residual standard error: 2667 on 46 degrees of freedom\n## Multiple R-squared:  0.03318,    Adjusted R-squared:  0.01216 \n## F-statistic: 1.579 on 1 and 46 DF,  p-value: 0.2153"},{"path":"lab-1-september-15.html","id":"fitting-an-intercept-only-model","chapter":"1 Lab 1 — September 15","heading":"1.2.8 Fitting an intercept-only model","text":"One way fitting intercept-model use lm() .dependent (response) variable remains area, right-hand side formula just\n1 indicate intercept.second way fitting intercept-model take advantage fact already\nbuilt simple linear regression model (rock_slr_model) obtain intercept-model \njust need \"remove\" shape variable formula specification. can accomplished\nusing update() function.formula specification , . refers \"everything already \". ,\n. left ~ refers area, . right ~ refers \n1 + shape (1 usually written since linear regression models fit \nintercept default, still exists!). Therefore, code says \nrock_intercept_model \"update\" rock_slr_model modification \nformula now area ~ 1 + shape - shape, resulting area ~ 1. can verify \nfact needed calling:update() function extremely useful start working multiple linear\nregression models variable selection procedures later course sometimes\neasier specify variables want rather ones want.output , equation fitted line :\\[\\widehat{y}_{} \\,=\\, 7187.7, \\quad =1,\\ldots,n\\]","code":"\nrock_intercept_model <- lm(area ~ 1, data=rock)\nrock_intercept_model <- update(rock_slr_model, formula = . ~ . - shape)\nformula(rock_intercept_model)## area ~ 1\nsummary(rock_intercept_model)## \n## Call:\n## lm(formula = area ~ 1, data = rock)\n## \n## Residuals:\n##     Min      1Q  Median      3Q     Max \n## -6171.7 -1882.5   299.3  1681.8  5024.3 \n## \n## Coefficients:\n##             Estimate Std. Error t value Pr(>|t|)    \n## (Intercept)   7187.7      387.4   18.55   <2e-16 ***\n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Residual standard error: 2684 on 47 degrees of freedom"},{"path":"lab-1-september-15.html","id":"visualising-the-intercept-only-fit","chapter":"1 Lab 1 — September 15","heading":"1.2.9 Visualising the intercept-only fit","text":"can draw scatterplot data area y-axis shape x-axis, \noverlay intercept-fit. drawing lines base-R graphics, recall need sort\nx-values (reorder corresponding y-values)! example, since fitted values\nconstant values shape, need reorder fitted values \ncorresponding shape values — shape values need sorted. However, \nsake consistency, sort shape values reorder corresponding fitted values.fitted values intercept-model can obtained wrapping model \nfitted() function.Now, making plot:","code":"\nfitted(rock_intercept_model)##        1        2        3        4        5        6        7        8 \n## 7187.729 7187.729 7187.729 7187.729 7187.729 7187.729 7187.729 7187.729 \n##        9       10       11       12       13       14       15       16 \n## 7187.729 7187.729 7187.729 7187.729 7187.729 7187.729 7187.729 7187.729 \n##       17       18       19       20       21       22       23       24 \n## 7187.729 7187.729 7187.729 7187.729 7187.729 7187.729 7187.729 7187.729 \n##       25       26       27       28       29       30       31       32 \n## 7187.729 7187.729 7187.729 7187.729 7187.729 7187.729 7187.729 7187.729 \n##       33       34       35       36       37       38       39       40 \n## 7187.729 7187.729 7187.729 7187.729 7187.729 7187.729 7187.729 7187.729 \n##       41       42       43       44       45       46       47       48 \n## 7187.729 7187.729 7187.729 7187.729 7187.729 7187.729 7187.729 7187.729\nsorted_shape <- sort(rock$shape)\nordered_fitted <- fitted(rock_intercept_model)[order(rock$shape)]\n\nplot(area ~ shape, data=rock, main=\"Intercept-only model\")\nlines(x=sorted_shape, y=ordered_fitted, col=\"darkred\", lwd=2)"},{"path":"lab-1-september-15.html","id":"visual-diagnostics","chapter":"1 Lab 1 — September 15","heading":"1.2.10 Visual diagnostics","text":"","code":""},{"path":"lab-1-september-15.html","id":"the-residual-vs.-predictor-plot","chapter":"1 Lab 1 — September 15","heading":"1.2.10.1 The residual vs. predictor plot","text":"identify potential issues intercept-model, can make plot residuals,\n\\(e_{} \\,=\\, Y_{} \\,-\\, \\widehat{Y}_{}\\), predictor values (shape).residual values intercept-model can obtained wrapping model \nresid() function.Now, making plot:assumptions linear regression, discernable patterns/trends \nplotted points. addition, plot look like random scatter \\(y=0\\) constant\nvariance. plot , appear patterns/trends \nplotted points. plot appears random scatter \\(y=0\\) constant variance.","code":"\nresid(rock_intercept_model)##          1          2          3          4          5          6          7 \n## -2197.7292  -185.7292   370.2708   164.2708   755.2708   791.2708  2145.2708 \n##          8          9         10         11         12         13         14 \n##  1021.2708  1205.2708  -762.7292  2176.2708  1436.2708  3463.2708  1680.2708 \n##         15         16         17         18         19         20         21 \n##  2229.2708  1686.2708  3774.2708  3555.2708  4690.2708  2679.2708   650.2708 \n##         22         23         24         25         26         27         28 \n##  4688.2708  5024.2708  1045.2708  -827.7292 -2994.7292   228.2708 -1941.7292 \n##         29         30         31         32         33         34         35 \n##  -678.7292 -2292.7292  -412.7292   706.2708 -1207.7292 -1869.7292   204.2708 \n##         36         37         38         39         40         41         42 \n##   706.2708 -3718.7292 -5719.7292 -3663.7292 -1920.7292 -2139.7292 -6171.7292 \n##         43         44         45         46         47         48 \n## -1582.7292  1605.2708 -3712.7292 -5536.7292 -1673.7292  2530.2708\nplot(\n  resid(rock_intercept_model) ~ shape, data=rock,\n  main=\"Residuals vs Predictor\", xlab=\"shape\", ylab=\"residuals\"\n)"},{"path":"lab-1-september-15.html","id":"the-residual-vs.-fitted-plot","chapter":"1 Lab 1 — September 15","heading":"1.2.10.2 The residual vs. fitted plot","text":"identify potential issues intercept-model, can also make plot residuals,\n\\(e_{} \\,=\\, Y_{} \\,-\\, \\widehat{Y}_{}\\), fitted values., discernable patterns/trends plotted points, plot\nlook like random scatter \\(y=0\\) constant variance. plot look bit\nstrange, fitted line constant! residuals appear scattered\n\\(y=0\\) equal variance, seem issues .","code":"\nplot(\n  resid(rock_intercept_model) ~ fitted(rock_intercept_model),\n  main=\"Residuals vs Fitted\", xlab=\"fitted values\", ylab=\"residuals\"\n)"},{"path":"lab-1-september-15.html","id":"normality-of-residuals","chapter":"1 Lab 1 — September 15","heading":"1.2.10.3 Normality of residuals","text":"also assumption residuals normally distributed. can checked \ncreating QQ-plot residuals overlaying QQ-line.Strong deviation QQ-line evidence violation normality assumption. \ncase plot, reason believe residuals \nnormally distributed.","code":"\nqqnorm(resid(rock_intercept_model))\nqqline(resid(rock_intercept_model), col=\"darkred\", lwd=2)"},{"path":"lab-3-september-29.html","id":"lab-3-september-29","chapter":"2 Lab 3 — September 29","heading":"2 Lab 3 — September 29","text":"","code":""},{"path":"lab-3-september-29.html","id":"some-modern-data-science-packages","chapter":"2 Lab 3 — September 29","heading":"2.1 Some modern data science packages","text":"Tidyverse collection packages modern data\nscience. Tidymodels another collection packages \nextends tidyverse modelling. labs, \nusing entire tidyverse tidymodels. now, recommend installing \ncomponent packages.tibble, dplyr,\nggplot2, broom. \npackages can installed using:successfully installing packages, can load using:Additionally, ggplot2 comes various plotting themes (examples\ncan found ). \ndefault, plotting background grey prefer white background also call:tibble package provides us usage \"tibbles\" \nextension base-R data frame. many features, mostly using tibbles\npretty-printing features \nfact integrates well packages.dplyr package provides us tools data wrangling \nbase-R equivalents can feel bit clunky. Examples data wrangling include: adding/removing\nobservations based presence/absence one conditions, creating additional variables\ndata set, condensing existing data summaries.ggplot2 package alternative base-R graphics\nfunctions \"smarter\" exist base-R. example, previous\nlab, mentioned plotting lines base-R, points needed sorted left right\nsince lines() function joins points order appear. Without sorting, \nresulting line appear jagged unevenly coloured certain areas. \nggplot2, separate functions joining points \nappear data joining points order left right.broom package contains tools cleaning model output \nextracting model data diagnostic information ready visualisation \nggplot2.","code":"\ninstall.packages(\"tibble\")\ninstall.packages(\"dplyr\")\ninstall.packages(\"ggplot2\")\ninstall.packages(\"broom\")\nlibrary(tibble)\nlibrary(dplyr)\nlibrary(ggplot2)\nlibrary(broom)\ntheme_set(theme_bw())"},{"path":"lab-3-september-29.html","id":"back-to-simple-linear-regression","chapter":"2 Lab 3 — September 29","heading":"2.2 Back to simple linear regression","text":"","code":""},{"path":"lab-3-september-29.html","id":"the-mpg-data-set","chapter":"2 Lab 3 — September 29","heading":"2.2.1 The mpg data set","text":"Consider fuel economy data set found ggplot2 package.\ncan load data set calling:Suppose interested fitting simple linear regression model highway miles per gallon\n(hwy) response variable city miles per gallon (cty) predictor variable.\nfitting model, check see linear relationship \nchosen variables.","code":"\ndata(mpg, package=\"ggplot2\")"},{"path":"lab-3-september-29.html","id":"check-for-a-linear-relationship","chapter":"2 Lab 3 — September 29","heading":"2.2.2 Check for a linear relationship","text":"create plot, use function ggplot.call ggplot can thought initialisation drawing canvasThe first argument ggplot data set, mpgThe second argument ggplot mapping, .e. \"variables contain data \ninterested plotting?\"mapping created supplying names variables found within data set \naesthetics function, aes().Finally, can add (\"plus\" symbol) layer points geom_point() inherit\naesthetics supplied initialisation canvasIn words, specified within geom_point(), points drawn positions\nx=cty y=hwyFrom plot , appears linear relationship two variables. can\nbegin fitting linear model.","code":"\nggplot(mpg, aes(x=cty, y=hwy))+\n  geom_point()"},{"path":"lab-3-september-29.html","id":"fitting-the-linear-model","chapter":"2 Lab 3 — September 29","heading":"2.2.3 Fitting the linear model","text":"regression output, \\(\\widehat{\\beta}_{0} = 0.892\\) \n\\(\\widehat{\\beta}_{1} = 1.337\\). equation fitted line :\\[\\widehat{y}_{} \\,=\\, 0.892 \\,+\\, 1.337x_{}\\]can interpret \\(\\widehat{\\beta}_{0} = 0.892\\) mean highway miles per gallon city\nmiles per gallon value zero. However, really make sense context \ndata since car travels zero city miles gallon gas.can interpret \\(\\widehat{\\beta}_{1} = 1.337\\) mean change highway miles per gallon per\nunit increase city miles per gallon. , 1 mpg increase city mpg, expect 1.337\nmpg increase highway mpg.","code":"\nlm_miles <- lm(hwy ~ cty, data=mpg)\n\nsummary(lm_miles)## \n## Call:\n## lm(formula = hwy ~ cty, data = mpg)\n## \n## Residuals:\n##     Min      1Q  Median      3Q     Max \n## -5.3408 -1.2790  0.0214  1.0338  4.0461 \n## \n## Coefficients:\n##             Estimate Std. Error t value Pr(>|t|)    \n## (Intercept)  0.89204    0.46895   1.902   0.0584 .  \n## cty          1.33746    0.02697  49.585   <2e-16 ***\n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Residual standard error: 1.752 on 232 degrees of freedom\n## Multiple R-squared:  0.9138, Adjusted R-squared:  0.9134 \n## F-statistic:  2459 on 1 and 232 DF,  p-value: < 2.2e-16"},{"path":"lab-3-september-29.html","id":"visualising-the-fit","chapter":"2 Lab 3 — September 29","heading":"2.2.4 Visualising the fit","text":"ggplot2 broom\nshine! first use broom::augment() linear model extract data used \nfit model, along additional diagnostics (residuals). Note \nbroom::augment() generic function. pass lm object broom::augment(), \nhood, actually calls specific broom::augment.lm() function.first two columns lm_miles_aug, recovered data initially passed\nlm(). .fitted column contains fitted values model .resid column\ncontains raw residuals.plot wish build use newly created lm_miles_aug data set \nfollowing features:base plot scatterplot points located x=cty y=hwyThe fitted line drawn top points located x=cty y=.fittedSince points lines wish draw longer share common y-aesthetic, may \nwant declare y-aesthetic initialisation canvas, instead, declare \ny-aesthetic individual layers.Notice building plot, sort points! default, geom_line()\nconnects points left right. added additional arguments geom_line() outside\naesthetics since values depend data:colour controls colour line (can also use color)lwd controls width line (can also use linewidth)alpha controls transparency lineTo see construction plot \"addition layers\" can runfollowed byfollowed ","code":"\nlm_miles_aug <- augment(lm_miles)\n\nlm_miles_aug## # A tibble: 234 x 8\n##      hwy   cty .fitted .resid    .hat .sigma     .cooksd .std.resid\n##    <int> <int>   <dbl>  <dbl>   <dbl>  <dbl>       <dbl>      <dbl>\n##  1    29    18    25.0 4.03   0.00458   1.74 0.0123          2.31  \n##  2    29    21    29.0 0.0214 0.00834   1.76 0.000000632     0.0123\n##  3    31    20    27.6 3.36   0.00661   1.74 0.0123          1.92  \n##  4    30    21    29.0 1.02   0.00834   1.75 0.00144         0.585 \n##  5    26    16    22.3 3.71   0.00445   1.74 0.0101          2.12  \n##  6    26    18    25.0 1.03   0.00458   1.75 0.000805        0.591 \n##  7    27    18    25.0 2.03   0.00458   1.75 0.00311         1.16  \n##  8    26    18    25.0 1.03   0.00458   1.75 0.000805        0.591 \n##  9    25    16    22.3 2.71   0.00445   1.75 0.00536         1.55  \n## 10    28    20    27.6 0.359  0.00661   1.76 0.000140        0.205 \n## # ... with 224 more rows\n\nggplot(lm_miles_aug, aes(x=cty))+\n  geom_point(aes(y=hwy))+\n  geom_line(aes(y=.fitted), colour=\"#3366FF\", lwd=1.5, alpha=0.6)\nggplot(lm_miles_aug, aes(x=cty))\nggplot(lm_miles_aug, aes(x=cty))+\n  geom_point(aes(y=hwy))\nggplot(lm_miles_aug, aes(x=cty))+\n  geom_point(aes(y=hwy))+\n  geom_line(aes(y=.fitted), colour=\"#3366FF\", lwd=1.5, alpha=0.6)"},{"path":"lab-3-september-29.html","id":"confidence-and-prediction-intervals","chapter":"2 Lab 3 — September 29","heading":"2.2.5 Confidence and prediction intervals","text":"","code":""},{"path":"lab-3-september-29.html","id":"confidence-intervals","chapter":"2 Lab 3 — September 29","heading":"2.2.5.1 Confidence intervals","text":"Suppose interested finding point estimate 95% confidence interval mean\nhighway miles per gallon vehicles city miles per gallon value 20. can obtain \nvalues using predict() function. predict() another example generic function. \npass lm object predict(), actually calls specific predict.lm() function.\nsee need get point estimate confidence interval, pull associated\ndocumentation.need supply predict():linear model objectA data frame containing variables common linear model, values upon predict\nNote model predictor variable cty, supply\nnewdata = data.frame(x=20), must supply newdata = data.frame(cty=20)\nNote model predictor variable cty, supply\nnewdata = data.frame(x=20), must supply newdata = data.frame(cty=20)want confidence interval, specify interval = \"confidence\"default confidence level 0.95From output, point estimate 27.641. lower bound 95% confidence interval\n27.360 upper bound 27.922. says 95% confidence, vehicles \ncity miles per gallon value 20, mean highway miles per gallon range 27.360 \n27.922.","code":"\n?predict.lm\npredict(\n  lm_miles,\n  newdata = data.frame(cty=20),\n  interval = \"confidence\"\n)##        fit      lwr      upr\n## 1 27.64115 27.36044 27.92187"},{"path":"lab-3-september-29.html","id":"prediction-intervals","chapter":"2 Lab 3 — September 29","heading":"2.2.5.2 Prediction intervals","text":"Suppose now interested finding point estimate 95% prediction interval \nhighway miles per gallon vehicle city miles per gallon 20. can obtain \nvalues manner similar previous example:output, point estimate 27.641. lower bound 95% prediction interval\n24.177 upper bound 31.105. says 95% confidence, vehicle city\nmiles per gallon value 20 highway miles per gallon value 24.177 31.105.","code":"\npredict(\n  lm_miles,\n  newdata = data.frame(cty=20),\n  interval = \"prediction\"\n)##        fit      lwr      upr\n## 1 27.64115 24.17733 31.10498"},{"path":"lab-3-september-29.html","id":"spot-the-differences","chapter":"2 Lab 3 — September 29","heading":"2.2.5.3 Spot the differences","text":"point estimates cases identical. However, lower upper bounds \nconfidence prediction intervals different. unsurprising since formulas used \ncompute bounds two intervals different.noted , general, fixed confidence level, prediction interval \nwider corresponding confidence interval.","code":""},{"path":"lab-3-september-29.html","id":"correlations","chapter":"2 Lab 3 — September 29","heading":"2.2.6 Correlations","text":"Using previously obtained augmented model data (lm_miles_aug), can easily obtain \ncorrelations \\(X_{}\\) \\(Y_{}\\),\\(Y_{}\\) \\(\\widehat{Y}_{}\\),\\(X_{}\\) \\(\\widehat{Y}_{}\\),compare among , compare model's coefficient determination,\n\\(R^{2}\\). Correlations obtained using cor() function. also use summarise()\nfunction dplyr package help us obtain correlations\nstaying context augmented data can reference variables using bare\nnames (.e. need use $ reference variables).Note also :values mathematically related coincidence? 😲 (See assignment 2\nquestion 3).","code":"\nsummarise(\n  lm_miles_aug,\n  corr_x_y = cor(cty, hwy),\n  corr_y_fitted = cor(hwy, .fitted),\n  corr_x_fitted = cor(cty, .fitted)\n)## # A tibble: 1 x 3\n##   corr_x_y corr_y_fitted corr_x_fitted\n##      <dbl>         <dbl>         <dbl>\n## 1    0.956         0.956             1\n\nsummarise(\n  lm_miles_aug,\n  corr_x_y_squared = cor(cty, hwy)^2,\n  corr_y_fitted_squared = cor(hwy, .fitted)^2,\n  corr_x_fitted_squared = cor(cty, .fitted)^2,\n  r.squared = summary(lm_miles)$r.squared\n)## # A tibble: 1 x 4\n##   corr_x_y_squared corr_y_fitted_squared corr_x_fitted_squared r.squared\n##              <dbl>                 <dbl>                 <dbl>     <dbl>\n## 1            0.914                 0.914                     1     0.914\n"},{"path":"lab-3-september-29.html","id":"simple-linear-regression-with-transformations","chapter":"2 Lab 3 — September 29","heading":"2.3 Simple linear regression with transformations","text":"applying transformations variables linear models, two options:Create new variable data set applies transformation, orApply transformation formula specificationTo observe differences, build two models using methods. Using mpg data set\n, let us fit model response engine displacement predictor \n(natural) log highway miles per gallon.","code":""},{"path":"lab-3-september-29.html","id":"creating-a-new-variable-in-your-data-set","chapter":"2 Lab 3 — September 29","heading":"2.3.1 Creating a new variable in your data set","text":"dplyr loaded, can easily create new variables data set using mutate()\nfunction. first argument mutate() data set. Additional arguments name-value\npairs variables want create.model created usual:","code":"\nmpg2 <- mutate(\n  mpg,\n  log_hwy = log(hwy)\n)\nlm_displ1 <- lm(displ ~ log_hwy, data=mpg2)"},{"path":"lab-3-september-29.html","id":"applying-the-transformation-in-the-formula-specification","chapter":"2 Lab 3 — September 29","heading":"2.3.2 Applying the transformation in the formula specification","text":"can apply transformations formula specification wish create new\nvariable ahead time. model created using:","code":"\nlm_displ2 <- lm(displ ~ log(hwy), data=mpg2)"},{"path":"lab-3-september-29.html","id":"comparing-our-two-models","chapter":"2 Lab 3 — September 29","heading":"2.3.3 Comparing our two models","text":"models identical! try predict engine displacement vehicle \nhighway miles per gallon value 29.predicted values different! ?models use variables created ahead time, value(s) supplied predict upon\nmust scale predictor values used fitting model.\nwords, supplying value 29 first model, predicting engine displacement\nvehicle log highway miles per gallon value 29! order properly predict \nengine displacement, must instead supply value log(29).models transformations applied formula specification, can supply values \noriginal scale transformation applied us calculating predicted value.","code":"\nsummary(lm_displ1)## \n## Call:\n## lm(formula = displ ~ log_hwy, data = mpg2)\n## \n## Residuals:\n##     Min      1Q  Median      3Q     Max \n## -1.2992 -0.5548 -0.1148  0.4252  3.7446 \n## \n## Coefficients:\n##             Estimate Std. Error t value Pr(>|t|)    \n## (Intercept)  15.4145     0.6496   23.73   <2e-16 ***\n## log_hwy      -3.8260     0.2074  -18.45   <2e-16 ***\n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Residual standard error: 0.8243 on 232 degrees of freedom\n## Multiple R-squared:  0.5946, Adjusted R-squared:  0.5929 \n## F-statistic: 340.3 on 1 and 232 DF,  p-value: < 2.2e-16\nsummary(lm_displ2)## \n## Call:\n## lm(formula = displ ~ log(hwy), data = mpg2)\n## \n## Residuals:\n##     Min      1Q  Median      3Q     Max \n## -1.2992 -0.5548 -0.1148  0.4252  3.7446 \n## \n## Coefficients:\n##             Estimate Std. Error t value Pr(>|t|)    \n## (Intercept)  15.4145     0.6496   23.73   <2e-16 ***\n## log(hwy)     -3.8260     0.2074  -18.45   <2e-16 ***\n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Residual standard error: 0.8243 on 232 degrees of freedom\n## Multiple R-squared:  0.5946, Adjusted R-squared:  0.5929 \n## F-statistic: 340.3 on 1 and 232 DF,  p-value: < 2.2e-16\npredict(\n  lm_displ1,\n  newdata = data.frame(log_hwy=29)\n)##         1 \n## -95.53829\npredict(\n  lm_displ2,\n  newdata = data.frame(hwy=29)\n)##       1 \n## 2.53138\npredict(\n  lm_displ1,\n  newdata = data.frame(log_hwy=log(29))\n)##       1 \n## 2.53138"},{"path":"lab-3-september-29.html","id":"warning","chapter":"2 Lab 3 — September 29","heading":"2.3.4 Warning ❗","text":"operations applied formula specification treated mathematical\noperations. example, + formula specification means add variable saw\nsection 1.2.8, - means remove variable. addition, ^ symbol usually use\nexponentiation different meaning used formula specification. example, \nwanted fit model using square highway miles per gallon predictor, \nwrite:Instead, must either create variable ahead time wrap exponentiation ():operation wrapped () formula specification, means treat literal\nmathematical operator rather formula operator.","code":"\nlm(displ ~ hwy^2, data=mpg2)\nlm(displ ~ I(hwy^2), data=mpg2)"},{"path":"lab-3-september-29.html","id":"another-example","chapter":"2 Lab 3 — September 29","heading":"2.4 Another example","text":"sake illustration, suppose wish fit model response variable \nlog highway miles per gallon plus log city miles per gallon predictor\nvariable square engine displacement. create response variable ahead\ntime apply transformation predictor formula specification.model fitted using:equation fitted line :\\[\\widehat{y}_{} \\,=\\, 6.445 \\,-\\, 0.039x_{}^{2}\\]\\(\\widehat{y}_{}\\) sum log highway miles per gallon log city miles per\ngallon. Due model constructed, wanted predict sum log highway\nmiles per gallon log city highway miles per gallon particular vehicle, supply\ndisplacement values -model square .","code":"\nmpg2 <- mutate(\n  mpg2,\n  mpg_sum = log(hwy) + log(cty)\n)\nlm_log_miles <- lm(mpg_sum ~ I(displ^2), data=mpg2)\n\nsummary(lm_log_miles)## \n## Call:\n## lm(formula = mpg_sum ~ I(displ^2), data = mpg2)\n## \n## Residuals:\n##      Min       1Q   Median       3Q      Max \n## -0.91040 -0.18887  0.00019  0.16808  1.33149 \n## \n## Coefficients:\n##              Estimate Std. Error t value Pr(>|t|)    \n## (Intercept)  6.444537   0.037335  172.61   <2e-16 ***\n## I(displ^2)  -0.038570   0.002214  -17.42   <2e-16 ***\n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Residual standard error: 0.3324 on 232 degrees of freedom\n## Multiple R-squared:  0.5668, Adjusted R-squared:  0.5649 \n## F-statistic: 303.6 on 1 and 232 DF,  p-value: < 2.2e-16"},{"path":"lab-3-september-29.html","id":"visualise-the-fit","chapter":"2 Lab 3 — September 29","heading":"2.4.1 Visualise the fit","text":"can visualise fit using procedure first augmenting linear model.two things note :name column predictor values violates usual naming conventions containing\nbrackets caret name wrapped backticksThe values column squared displacement valuesThis can verified comparing values lm_log_miles_aug values mpg2 —\nrows reordered way , example, first row lm_log_miles_aug\ncorresponds first row mpg2We can visualise fit passing augmented model data ggplot():Obviously, great fit goal example!","code":"\nlm_log_miles_aug <- augment(lm_log_miles)\n\nlm_log_miles_aug## # A tibble: 234 x 7\n##    mpg_sum `I(displ^2)` .fitted    .hat .sigma    .cooksd .std.resid\n##      <dbl>     <I<dbl>>   <dbl>   <dbl>  <dbl>      <dbl>      <dbl>\n##  1    6.26         3.24    6.32 0.00914  0.333 0.000162      -0.187 \n##  2    6.41         3.24    6.32 0.00914  0.333 0.000359       0.279 \n##  3    6.43         4       6.29 0.00846  0.333 0.000758       0.421 \n##  4    6.45         4       6.29 0.00846  0.333 0.000941       0.470 \n##  5    6.03         7.84    6.14 0.00580  0.333 0.000330      -0.336 \n##  6    6.15         7.84    6.14 0.00580  0.333 0.00000106     0.0191\n##  7    6.19         9.61    6.07 0.00502  0.333 0.000290       0.339 \n##  8    6.15         3.24    6.32 0.00914  0.333 0.00123       -0.517 \n##  9    5.99         3.24    6.32 0.00914  0.332 0.00454       -0.992 \n## 10    6.33         4       6.29 0.00846  0.333 0.0000553      0.114 \n## # ... with 224 more rows\n\nggplot(lm_log_miles_aug, aes(x=`I(displ^2)`))+\n  geom_point(aes(y=mpg_sum))+\n  geom_line(aes(y=.fitted), colour=\"#3366FF\", lwd=1.5, alpha=0.6)"},{"path":"lab-5-october-13.html","id":"lab-5-october-13","chapter":"3 Lab 5 — October 13","heading":"3 Lab 5 — October 13","text":"","code":""},{"path":"lab-5-october-13.html","id":"packages","chapter":"3 Lab 5 — October 13","heading":"3.1 Packages","text":"tidyr package another component package \ntidyverse contains functions cleaning \nreshaping data.penguins data set palmerpenguins\npackage used practice multiple linear regression.using package ellipse. package\ncontains functions drawing confidence regions associated estimates obtained linear\nregression. Unlike code provided class drawing confidence regions took raw data\ninput, ellipse::ellipse.lm() function allow pass linear model object\ninstead. using ellipse package, however\nneed draw lines component confidence intervals (though \ndifficult ).","code":"\nlibrary(tibble)\nlibrary(dplyr)\nlibrary(ggplot2)\nlibrary(tidyr)\nlibrary(broom)\nlibrary(ellipse)\nlibrary(palmerpenguins)\ntheme_set(theme_bw())"},{"path":"lab-5-october-13.html","id":"the-pipe","chapter":"3 Lab 5 — October 13","heading":"3.2 The pipe","text":"pipe operator, %>%, can found package magrittr,\ninstalled installed dplyr\npackage. dplyr loaded (calling library(dplyr)),\nmagrittr pipe also imported.pipe works taking result left passing first argument \nfunction right. pipe allows write cleaner code converting something like ::revealing underlying sequential logic workflow. Since pipe works taking \nresult left passing first argument function right, use \npipe wrangling data dplyr especially convenient \ndplyr data wrangling functions data frame argument \nfirst argument, cases, return data frame.example , first argument filter(), select(), mutate() data frame.\nevaluation, function also returns data frame. Notice result piping data\nframe functions, need actually specify going (since \ngoes first argument default) need create extra variables intermediate\nsteps.","code":"\nmutate(select(filter(mydata, var1 > 5), var2, var3), var4 = var2 + sqrt(var3))\nmydata %>%\n  filter(var1 > 5) %>%\n  select(var2, var3) %>%\n  mutate(var4 = var2 + sqrt(var3))"},{"path":"lab-5-october-13.html","id":"multiple-linear-regression-hypothesis-testing","chapter":"3 Lab 5 — October 13","heading":"3.3 Multiple linear regression — hypothesis testing","text":"","code":""},{"path":"lab-5-october-13.html","id":"the-penguins-data","chapter":"3 Lab 5 — October 13","heading":"3.3.1 The penguins data","text":"Let us load penguins data set. variables interested working \ncontain missing values. Immediately loading data, can pass drop_na()\nfunction (tidyr) drop rows (observations) \ncontain missing values.addition, also rename variables shorten code need \ntype. can done piping data rename() function supplying name pairs\nformat new_name = old_name.","code":"\npenguins <- palmerpenguins::penguins %>%\n  drop_na() %>%\n  rename(\n    bill_length = bill_length_mm,\n    bill_depth = bill_depth_mm,\n    flipper_length = flipper_length_mm,\n    body_mass = body_mass_g\n  )\n\npenguins## # A tibble: 333 x 8\n##    species island    bill_length bill_depth flipper_length body_mass sex    year\n##    <fct>   <fct>           <dbl>      <dbl>          <int>     <int> <fct> <int>\n##  1 Adelie  Torgersen        39.1       18.7            181      3750 male   2007\n##  2 Adelie  Torgersen        39.5       17.4            186      3800 fema~  2007\n##  3 Adelie  Torgersen        40.3       18              195      3250 fema~  2007\n##  4 Adelie  Torgersen        36.7       19.3            193      3450 fema~  2007\n##  5 Adelie  Torgersen        39.3       20.6            190      3650 male   2007\n##  6 Adelie  Torgersen        38.9       17.8            181      3625 fema~  2007\n##  7 Adelie  Torgersen        39.2       19.6            195      4675 male   2007\n##  8 Adelie  Torgersen        41.1       17.6            182      3200 fema~  2007\n##  9 Adelie  Torgersen        38.6       21.2            191      3800 male   2007\n## 10 Adelie  Torgersen        34.6       21.1            198      4400 male   2007\n## # ... with 323 more rows\n"},{"path":"lab-5-october-13.html","id":"subsetting-the-data","chapter":"3 Lab 5 — October 13","heading":"3.3.2 Subsetting the data","text":"data set contains penguins three species across three islands:following example, let us focus penguins species Adelie island\nBiscoe. can obtain subset penguins data using following code:(Note code , using two equal signs since making comparison \nsetting values).","code":"\npenguins %>%\n  distinct(species, island)## # A tibble: 5 x 2\n##   species   island   \n##   <fct>     <fct>    \n## 1 Adelie    Torgersen\n## 2 Adelie    Biscoe   \n## 3 Adelie    Dream    \n## 4 Gentoo    Biscoe   \n## 5 Chinstrap Dream\n\nadeliebiscoe <- penguins %>%\n  filter(species == \"Adelie\", island == \"Biscoe\")"},{"path":"lab-5-october-13.html","id":"visual-check-for-linear-relationship","chapter":"3 Lab 5 — October 13","heading":"3.3.3 Visual check for linear relationship","text":"Suppose interested fitting model using body mass response bill length, bill\ndepth, flipper length predictors. building model, verify \nlinear relationship response individual predictors.plots look okay. go ahead fit model.","code":"\nggplot(adeliebiscoe, aes(x=bill_length, y=body_mass))+\n  geom_point()\nggplot(adeliebiscoe, aes(x=bill_depth, y=body_mass))+\n  geom_point()\nggplot(adeliebiscoe, aes(x=flipper_length, y=body_mass))+\n  geom_point()"},{"path":"lab-5-october-13.html","id":"fit-the-model","chapter":"3 Lab 5 — October 13","heading":"3.3.4 Fit the model","text":"output, equation fitted line :\\[\\widehat{y}_{} \\,=\\, -6122 \\,+\\, 70.743x_{1,\\,} \\,+\\, 165.196x_{2,\\,} + 21.397x_{3,\\,}\\]:\\(\\widehat{y}_{}\\) predicted body mass\\(x_{1,\\,}\\) bill length\\(x_{2,\\,}\\) bill depth\\(x_{3,\\,}\\) flipper length","code":"\nad_lm <- lm(body_mass ~ bill_length + bill_depth + flipper_length, data=adeliebiscoe)\n\nsummary(ad_lm)## \n## Call:\n## lm(formula = body_mass ~ bill_length + bill_depth + flipper_length, \n##     data = adeliebiscoe)\n## \n## Residuals:\n##     Min      1Q  Median      3Q     Max \n## -836.50 -186.29   19.01  183.14  486.90 \n## \n## Coefficients:\n##                 Estimate Std. Error t value Pr(>|t|)    \n## (Intercept)    -6122.000   1341.697  -4.563 4.71e-05 ***\n## bill_length       70.743     21.445   3.299 0.002046 ** \n## bill_depth       165.196     43.802   3.771 0.000526 ***\n## flipper_length    21.397      7.262   2.947 0.005336 ** \n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Residual standard error: 298.8 on 40 degrees of freedom\n## Multiple R-squared:  0.6508, Adjusted R-squared:  0.6246 \n## F-statistic: 24.85 on 3 and 40 DF,  p-value: 3.048e-09"},{"path":"lab-5-october-13.html","id":"fitting-a-model-without-an-intercept","chapter":"3 Lab 5 — October 13","heading":"3.3.5 Fitting a model without an intercept","text":"default, linear models fitted intercept. can fit linear model without \nintercept adding + 0 - 1 formula specification (see Details section \n?lm). make hypothesis tests next section bit interesting,\nlet us remove intercept model just fit overwrite .shown Lab 1, can fitting brand new model:using update():Recall line code means (new) ad_lm constructed taking \nexisting ad_lm updating formula. response variable remains (represented \ndot left tilde), predictors remain (represented dot \nright tilde) - 1 denotes want intercept.take look new model.Interestingly, removing intercept model, adjusted R-squared value went \n0.6246 0.9905 👀.","code":"\nad_lm <- lm(body_mass ~ bill_length + bill_depth + flipper_length - 1, data=adeliebiscoe)\nad_lm <- update(ad_lm, formula = . ~ . - 1)\nsummary(ad_lm)## \n## Call:\n## lm(formula = body_mass ~ bill_length + bill_depth + flipper_length - \n##     1, data = adeliebiscoe)\n## \n## Residuals:\n##     Min      1Q  Median      3Q     Max \n## -737.69 -296.78   41.82  236.37  769.39 \n## \n## Coefficients:\n##                Estimate Std. Error t value Pr(>|t|)  \n## bill_length      58.741     25.922   2.266   0.0288 *\n## bill_depth      125.323     52.276   2.397   0.0212 *\n## flipper_length   -4.635      5.471  -0.847   0.4018  \n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Residual standard error: 363.9 on 41 degrees of freedom\n## Multiple R-squared:  0.9912, Adjusted R-squared:  0.9905 \n## F-statistic:  1536 on 3 and 41 DF,  p-value: < 2.2e-16"},{"path":"lab-5-october-13.html","id":"anova-with-multiple-linear-regression-models","chapter":"3 Lab 5 — October 13","heading":"3.3.6 ANOVA with multiple linear regression models","text":"multiple linear regression, output resulting passing linear model anova() \nslightly different saw simple linear regression. simple linear regression,\nwrapping linear model anova() produced \"classic\" \\(F\\)-table: sum squares \nfirst row SSR, sum squares second row SSE, single\n\\(F\\)-value corresponding \\(p\\)-value.output, now three \\(F\\)-values three corresponding \\(p\\)-values! However, \ninterpretation slightly different. sum squares column represents sequential\nincrease SSR (decrease SSE) adding variable model came . \n:sum squares bill_length row increase SSR (decrease SSE) \nincluding bill_length model (base model intercept)sum squares bill_depth row increase SSR (decrease SSE) \nincluding bill_depth model already includes bill_lengthThe sum squares flipper_length row increase SSR (decrease SSE) \nincluding flipper_length model already includes bill_length bill_depthThe sum squares Residual row SSE model includes \nbill_length, bill_depth, flipper_lengthUsing output , wish perform hypothesis test check whether subset \nparameters different zero, need extra math. since using R,\nmath! can perform partial \\(F\\)-tests interested constructing\nreduced models (update() function becomes extremely handy).","code":"\nanova(ad_lm)## Analysis of Variance Table\n## \n## Response: body_mass\n##                Df    Sum Sq   Mean Sq   F value  Pr(>F)    \n## bill_length     1 609528281 609528281 4601.6610 < 2e-16 ***\n## bill_depth      1    683988    683988    5.1638 0.02837 *  \n## flipper_length  1     95065     95065    0.7177 0.40182    \n## Residuals      41   5430791    132458                      \n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1"},{"path":"lab-5-october-13.html","id":"at-least-one-parameter-non-zero","chapter":"3 Lab 5 — October 13","heading":"3.3.7 At least one parameter non-zero","text":"Suppose interested testing hypotheses:\\[H_{0}: \\beta_{1} \\,=\\, \\beta_{2} \\,=\\, \\beta_{3} \\,=\\, 0, \\quad\nH_{}: \\text{least one non-zero}\\]reduced model intercept-model passes origin.full model model predictors (ad_lm).test hypotheses, pass reduced full models anova():produces \\(F\\)-value 1535.8 numerator degrees freedom, 3, denominator degrees \nfreedom, 41. need use values since \\(p\\)-value also given. Using \nsignificance level \\(\\alpha = 0.05\\), since \\(p\\)-value less 0.05, reject null\nhypothesis conclude least one parameters non-zero , \nconsider constant \\((Y \\,=\\, 0)\\) model. important note hypothesis test tells us\nleast one parameter non-zero, tell us .hypothesis test null hypothesis parameters equal zero often known\ntest model usefulness. fail reject null hypothesis, suggests \ncurrent model substantial improvement constant \\((Y \\,=\\, c)\\) model.","code":"\nad_lm_origin_only <- update(ad_lm, formula = . ~ 0)\nanova(ad_lm_origin_only, ad_lm)## Analysis of Variance Table\n## \n## Model 1: body_mass ~ 1 - 1\n## Model 2: body_mass ~ bill_length + bill_depth + flipper_length - 1\n##   Res.Df       RSS Df Sum of Sq      F    Pr(>F)    \n## 1     44 615738125                                  \n## 2     41   5430791  3 610307334 1535.8 < 2.2e-16 ***\n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1"},{"path":"lab-5-october-13.html","id":"two-parameters-non-zero","chapter":"3 Lab 5 — October 13","heading":"3.3.8 Two parameters non-zero","text":"Suppose interested testing hypotheses:\\[H_{0}: \\beta_{2} \\,=\\, \\beta_{3} \\,=\\, 0, \\quad H_{}: \\text{least one non-zero}\\]reduced model model contains bill_length. can construct model using\nupdate() either specifying variables want:variables wantTo test hypotheses, pass reduced full models anova():produces \\(F\\)-value 2.9407 numerator degrees freedom, 2, denominator degrees\nfreedom, 41. Using usual significance level \\(\\alpha = 0.05\\), since \\(p\\)-value \ngreater 0.05, fail reject null hypothesis conclude insufficient\nevidence support claim least one \\(\\beta_{2}\\) \\(\\beta_{3}\\) non-zero.","code":"\n# Don't forget the no-intercept term!!\nad_lm1 <- update(ad_lm, formula = . ~ bill_length - 1)\nad_lm1 <- update(ad_lm, formula = . ~ . - bill_depth - flipper_length)\nanova(ad_lm1, ad_lm)## Analysis of Variance Table\n## \n## Model 1: body_mass ~ bill_length - 1\n## Model 2: body_mass ~ bill_length + bill_depth + flipper_length - 1\n##   Res.Df     RSS Df Sum of Sq      F  Pr(>F)  \n## 1     43 6209844                              \n## 2     41 5430791  2    779053 2.9407 0.06405 .\n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1"},{"path":"lab-5-october-13.html","id":"one-parameter-non-zero","chapter":"3 Lab 5 — October 13","heading":"3.3.9 One parameter non-zero","text":"Suppose interested testing hypotheses:\\[H_{0}: \\beta_{3} \\,=\\, 0, \\quad H_{}: \\beta_{3} \\,\\neq\\, 0\\]hypothesis can carried performing \\(F\\)-test \\(t\\)-test (\\(t\\)-test much\nsimpler). want perform \\(F\\)-test, take usual steps first constructing \nreduced model. reduced model model contains bill_length bill_depth. can\nconstruct model using update() removing flipper_length.test hypotheses, pass reduced full models anova():produces \\(F\\)-value 0.7177 numerator degrees freedom, 1, denominator degrees\nfreedom, 41. Using usual significance level \\(\\alpha = 0.05\\), since \\(p\\)-value \ngreater 0.05, fail reject null hypothesis conclude insufficient\nevidence support claim \\(\\beta_{3}\\) different zero.testing single parameter non-zero, done \\(t\\)-test, whose corresponding \\(p\\)-value\nread coefficient summary table.corresponding \\(p\\)-value \\(t\\)-test 0.402. Since \\(p\\)-value greater 0.05,\nfail reject null hypothesis .","code":"\nad_lm12 <- update(ad_lm, formula = . ~ . - flipper_length)\nanova(ad_lm12, ad_lm)## Analysis of Variance Table\n## \n## Model 1: body_mass ~ bill_length + bill_depth - 1\n## Model 2: body_mass ~ bill_length + bill_depth + flipper_length - 1\n##   Res.Df     RSS Df Sum of Sq      F Pr(>F)\n## 1     42 5525856                           \n## 2     41 5430791  1     95065 0.7177 0.4018\ntidy(ad_lm)## # A tibble: 3 x 5\n##   term           estimate std.error statistic p.value\n##   <chr>             <dbl>     <dbl>     <dbl>   <dbl>\n## 1 bill_length       58.7      25.9      2.27   0.0288\n## 2 bill_depth       125.       52.3      2.40   0.0212\n## 3 flipper_length    -4.64      5.47    -0.847  0.402\n"},{"path":"lab-5-october-13.html","id":"caution","chapter":"3 Lab 5 — October 13","heading":"3.3.10 Caution ❗","text":"Suppose output looked like:correct say:\\(p\\)-value test var2 different zero larger 0.05 fail reject\nnull hypothesis. \\(p\\)-value test var3 different zero larger 0.05 \nfail reject null hypothesis. Therefore can simultaneously remove var2 var3 \nmodel.\\(p\\)-value 0.497 corresponds testing var2 different zero, assuming var1 var3\nincluded model. Similarly, \\(p\\)-value 0.885 corresponds testing var3 different\nzero, assuming var1 var2 included model. Therefore proper procedure\nusing \\(t\\)-tests test single parameter non-zero, remove variable model\n(assuming failed reject null hypothesis), refit new model without variable, \nperform second \\(t\\)-test.","code":"## # A tibble: 3 x 5\n##   term  estimate std.error statistic p.value\n##   <chr> <chr>    <chr>     <chr>       <dbl>\n## 1 var1  ...      ...       ...        0.0001\n## 2 var2  ...      ...       ...        0.497 \n## 3 var3  ...      ...       ...        0.885\n"},{"path":"lab-5-october-13.html","id":"multiple-linear-regression-working-with-matrices-in-r","chapter":"3 Lab 5 — October 13","heading":"3.4 Multiple linear regression — working with matrices in R","text":"","code":""},{"path":"lab-5-october-13.html","id":"simple-linear-regression-simultaneous-confidence-regions","chapter":"3 Lab 5 — October 13","heading":"3.5 Simple linear regression — simultaneous confidence regions","text":"Let us return rock data set consider simple linear regression model area \nresponse variable peri predictor.Suppose interested constructing 90% confidence region \\((\\beta_{0}, \\beta_{1})\\) \nindividual 95% confidence intervals. can start obtaining path ellipse passing\nlinear model ellipse(). default confidence level ellipse 95% need \nmake slight adjustment value level parameter. addition, ellipse() returns \nmatrix coordinates path ellipse. Since passing coordinates \npath ellipse ggplot later, also convert data frame.values (Intercept) peri columns represent x- y-values, respectively,\npath ellipse. Note ellipse() another example generic function. \npassing linear model object (object class lm) ellipse(), calls specific\nellipse.lm().Now path ellipse, also need obtain point\n\\((\\widehat{\\beta}_{0},\\, \\widehat{\\beta}_{1})\\), individual 95% confidence intervals \n\\(\\beta_{0}\\) \\(\\beta_{1}\\). can obtain passing linear model tidy.lm() \nspecifying conf.int=TRUE obtain coefficient table corresponding 95% confidence\nintervals.can begin plotting, data reshaping. Recall plotting \nggplot(), need x-values one column y-values another column.need data frame estimate \\(\\beta_{0}\\) one column estimate \n\\(\\beta_{1}\\) another column.need data frame lower upper bounds confidence interval \\(\\beta_{0}\\)\nsingle column.need data frame lower upper bounds confidence interval \\(\\beta_{1}\\)\nsingle column.Now data \"shape\", can start building plot. plot constructed \ntaking advantage fact every geom_*() layer data argument. means\ncan use different data set layer plot. Since common data\nset common aesthetics shared layers, supply anything call\nggplot(). Try running code , layer layer, see plot constructed!","code":"\ndata(rock)\n\nslr_rock <- lm(area ~ peri, data=rock)\nellipse_path <- slr_rock %>%\n  ellipse(level=0.90) %>%\n  as_tibble()\n\nellipse_path## # A tibble: 100 x 2\n##    `(Intercept)`  peri\n##            <dbl> <dbl>\n##  1         3305.  1.63\n##  2         3239.  1.65\n##  3         3174.  1.67\n##  4         3107.  1.69\n##  5         3041.  1.71\n##  6         2974.  1.73\n##  7         2908.  1.74\n##  8         2842.  1.76\n##  9         2777.  1.78\n## 10         2714.  1.79\n## # ... with 90 more rows\n\ncoef_table <- slr_rock %>%\n  tidy(conf.int=TRUE)\n\ncoef_table## # A tibble: 2 x 7\n##   term        estimate std.error statistic  p.value conf.low conf.high\n##   <chr>          <dbl>     <dbl>     <dbl>    <dbl>    <dbl>     <dbl>\n## 1 (Intercept)  3052.     477.         6.40 7.26e- 8  2092.     4012.  \n## 2 peri            1.54     0.157      9.81 7.51e-13     1.23      1.86\n\ncoef_point <- coef_table %>%\n  pivot_wider(id_cols=c(term, estimate), names_from=term, values_from=estimate)\n\ncoef_point## # A tibble: 1 x 2\n##   `(Intercept)`  peri\n##           <dbl> <dbl>\n## 1         3052.  1.54\n\nbeta0 <- coef_table %>%\n  slice(1) %>%\n  pivot_longer(cols=contains(\"conf\"))\n\nbeta0## # A tibble: 2 x 7\n##   term        estimate std.error statistic      p.value name      value\n##   <chr>          <dbl>     <dbl>     <dbl>        <dbl> <chr>     <dbl>\n## 1 (Intercept)    3052.      477.      6.40 0.0000000726 conf.low  2092.\n## 2 (Intercept)    3052.      477.      6.40 0.0000000726 conf.high 4012.\n\nbeta1 <- coef_table %>%\n  slice(2) %>%\n  pivot_longer(cols=contains(\"conf\"))\n\nbeta1## # A tibble: 2 x 7\n##   term  estimate std.error statistic  p.value name      value\n##   <chr>    <dbl>     <dbl>     <dbl>    <dbl> <chr>     <dbl>\n## 1 peri      1.54     0.157      9.81 7.51e-13 conf.low   1.23\n## 2 peri      1.54     0.157      9.81 7.51e-13 conf.high  1.86\n\nggplot()+\n  geom_vline(data=beta0, aes(xintercept=value), colour=\"#3366FF\", lty=2)+\n  geom_hline(data=beta1, aes(yintercept=value), colour=\"#3366FF\", lty=2)+\n  geom_point(data=coef_point, aes(x=`(Intercept)`, y=peri), colour=\"red\")+\n  geom_path(data=ellipse_path, aes(x=`(Intercept)`, y=peri))+\n  labs(\n    x=\"Intercept\", y=\"Slope\",\n    caption=\"Solid line represents 90% confidence region. Dashed lines represent 95% confidence intervals.\"\n  )"}]
